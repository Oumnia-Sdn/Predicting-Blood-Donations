{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2338a5",
   "metadata": {},
   "source": [
    "# Inspecting transfusion.data file\n",
    "\n",
    "Blood transfusion saves lives - from replacing lost blood during major surgery or a serious injury to treating various illnesses and blood disorders. Ensuring that there's enough blood in supply whenever needed is a serious challenge for the health professionals. According to WebMD, \"about 5 million Americans need a blood transfusion every year\".\n",
    "\n",
    "Our dataset is from a mobile blood donation vehicle in Taiwan. The Blood Transfusion Service Center drives to different universities and collects blood as part of a blood drive. We want to predict whether or not a donor will give blood the next time the vehicle comes to campus.\n",
    "\n",
    "The data is stored in data/transfusion.data and it is structured according to RFMTC marketing model (a variation of RFM). First, let's inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0191ce44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recency (months),Frequency (times),Monetary (c.c. blood),Time (months),\"whether he/she donated blood in March 2007\"\r",
      "\r\n",
      "2 ,50,12500,98 ,1\r",
      "\r\n",
      "0 ,13,3250,28 ,1\r",
      "\r\n",
      "1 ,16,4000,35 ,1\r",
      "\r\n",
      "2 ,20,5000,45 ,1\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -n5 ../Predicting-Blood-Donations/data/transfusion.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c436b",
   "metadata": {},
   "source": [
    "# Setting the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab164c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "''' Data visualisation'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "''' Scikit-Learn'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram')\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.metrics import confusion_matrix\n",
    "''' Imbalanced Classes'''\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff6a6d",
   "metadata": {},
   "source": [
    "# loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b90ac98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>whether he/she donated blood in March 2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50                  12500             98   \n",
       "1                 0                 13                   3250             28   \n",
       "2                 1                 16                   4000             35   \n",
       "3                 2                 20                   5000             45   \n",
       "4                 1                 24                   6000             77   \n",
       "\n",
       "   whether he/she donated blood in March 2007  \n",
       "0                                           1  \n",
       "1                                           1  \n",
       "2                                           1  \n",
       "3                                           1  \n",
       "4                                           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we load the data into memory\n",
    "transfusion = pd.read_csv(\"../Predicting-Blood-Donations/data/transfusion.data\")\n",
    "transfusion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f4abf",
   "metadata": {},
   "source": [
    "# Inspecting the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a021156",
   "metadata": {},
   "source": [
    "It looks like our dataset uses RFM model. RFM stands for Recency, Frequency and Monetary Value and it is commonly used in marketing for identifying your best customers. In our case, our customers are blood donors.\n",
    "\n",
    "RFMTC is a variation of the RFM model. Below is a description of what each column means in our dataset:\n",
    "\n",
    "- R (Recency - months since the last donation)\n",
    "- F (Frequency - total number of donation)\n",
    "- M (Monetary - total blood donated in c.c.)\n",
    "- T (Time - months since the first donation)\n",
    "- a binary variable representing whether he/she donated blood in March 2007 (1 stands for donating blood; 0 stands for not donating blood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80f7c5e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 5 columns):\n",
      " #   Column                                      Non-Null Count  Dtype\n",
      "---  ------                                      --------------  -----\n",
      " 0   Recency (months)                            748 non-null    int64\n",
      " 1   Frequency (times)                           748 non-null    int64\n",
      " 2   Monetary (c.c. blood)                       748 non-null    int64\n",
      " 3   Time (months)                               748 non-null    int64\n",
      " 4   whether he/she donated blood in March 2007  748 non-null    int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 29.3 KB\n"
     ]
    }
   ],
   "source": [
    "transfusion.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665b252",
   "metadata": {},
   "source": [
    "All of our variables are numeric with no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22241ba",
   "metadata": {},
   "source": [
    "# Target  column and its incidence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93457ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Recency (months)', 'Frequency (times)', 'Monetary (c.c. blood)',\n",
       "       'Time (months)', 'whether he/she donated blood in March 2007'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfusion.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d97539f",
   "metadata": {},
   "source": [
    "We see that our target column is not standardly named. let's rename it as *'target'* so that it is convenient to work with, especially for TPOT kind of Algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef60a013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50                  12500             98   \n",
       "1                 0                 13                   3250             28   \n",
       "2                 1                 16                   4000             35   \n",
       "3                 2                 20                   5000             45   \n",
       "4                 1                 24                   6000             77   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfusion.rename(columns={'whether he/she donated blood in March 2007': 'target'}, inplace= True)\n",
    "transfusion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf121f",
   "metadata": {},
   "source": [
    "We want to predict whether or not the same donor will give blood the next time the vehicle comes to campus. The model for this is a binary classifier, meaning that there are only 2 possible outcomes:\n",
    "\n",
    "0. *the donor will not give blood*\n",
    "1. *he donor will give blood*\n",
    "\n",
    "Target incidence is defined as the number of cases of each individual target value in a dataset. That is, how many 0s in the target column compared to how many 1s? Target incidence gives us an idea of how balanced (or imbalanced) is our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dc5043e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.76\n",
       "1    0.24\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfusion.target.value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bfb4d5",
   "metadata": {},
   "source": [
    "target variable incidence signals that 0s occur 76% of the time. The column is quite unbalanced.\n",
    "\n",
    "We could for example downsample it or upsample it, but since we're dealing with blood donations context we'll leave it as it is while maintaining the same distribution in our train set. we'll use stratify parameter on the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006e7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(transfusion.drop(columns='target'), transfusion.target,\n",
    "                                                   test_size=0.3,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=transfusion.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95947ba1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.762906\n",
       "1    0.237094\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a64439",
   "metadata": {},
   "source": [
    "We're good. We managed to keep the same stratification of the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1682c",
   "metadata": {},
   "source": [
    "# Model selection using TPOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806efb21",
   "metadata": {},
   "source": [
    "I decided to use TPOT for this dataset to help me zero in on one model that we can optimize further on a latter step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e720cbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tpot in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (0.11.7)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from tpot) (1.0.2)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from tpot) (4.62.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from tpot) (1.0.1)\n",
      "Requirement already satisfied: stopit>=1.1.1 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: deap>=1.2 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from tpot) (1.3.1)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from tpot) (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from tpot) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from tpot) (1.19.5)\n",
      "Requirement already satisfied: update-checker>=0.16 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from tpot) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from pandas>=0.24.2->tpot) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from scikit-learn>=0.22.0->tpot) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from update-checker>=0.16->tpot) (2.26.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->tpot) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "880852ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oumniasadaouni/.pyenv/versions/3.8.6/envs/pix2pix/lib/python3.8/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df6e3804a144e83a9305a162c57e399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/220 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7934981684981685\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.7934981684981685\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.7934981684981685\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.7934981684981685\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.7934981684981685\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.7934981684981685\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.7934981684981685\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.7934981684981685\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.7954212454212455\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.7973443223443223\n",
      "\n",
      "Best pipeline: RandomForestClassifier(LogisticRegression(MLPClassifier(MinMaxScaler(input_matrix), alpha=0.1, learning_rate_init=0.01), C=0.001, dual=False, penalty=l2), bootstrap=True, criterion=gini, max_features=0.2, min_samples_leaf=8, min_samples_split=19, n_estimators=100)\n",
      "\n",
      "AUC score: 0.7494\n",
      "\n",
      "Best pipeline steps:\n",
      "1. MinMaxScaler()\n",
      "2. StackingEstimator(estimator=MLPClassifier(alpha=0.1, learning_rate_init=0.01,\n",
      "                                          random_state=42))\n",
      "3. StackingEstimator(estimator=LogisticRegression(C=0.001, random_state=42))\n",
      "4. RandomForestClassifier(max_features=0.2, min_samples_leaf=8,\n",
      "                       min_samples_split=19, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "\n",
    "#Instantiate the TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=10,\n",
    "                     population_size= 20,\n",
    "                     verbosity=2,\n",
    "                     scoring= ['roc_auc'],\n",
    "                     random_state=42,\n",
    "                     disable_update_check=True,\n",
    "                     early_stop =5\n",
    "                     )\n",
    "tpot.fit(X_train,y_train)\n",
    "\n",
    "#roc_auc score \n",
    "y_pred= tpot.predict_proba(X_test)[:,1]\n",
    "tpot_score = roc_auc_score(y_test , y_pred)\n",
    "print(f'\\nAUC score: {tpot_score:.4f}')\n",
    "\n",
    "\n",
    "# Print best pipeline steps\n",
    "print('\\nBest pipeline steps:', end='\\n')\n",
    "for idx, (name, transform) in enumerate(tpot.fitted_pipeline_.steps, start=1):\n",
    "    # Print idx and transform\n",
    "    print(f'{idx}. {transform}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a1b9a",
   "metadata": {},
   "source": [
    "Let's visualize the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbd133b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "#plotting the roc curve \n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot([0,1], [0,1], 'k--');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66f748",
   "metadata": {},
   "source": [
    "letting our tpot wander in a broad range of possible ML models, the result came out to be a multilayer stacking ensemble with an MLPClassifier and LogisticRegression as estimators and RandomForestClassifier as a final estimator. This pipeline started with a preprocessing using MinMaxScaler of the data. \n",
    "\n",
    "Our AUC score is 75%, which is not bad at all! This score signals that there is 75% chance that the model will correctly distinguish a doner's willingness to actually give blood. \n",
    "\n",
    "Our last step would be to rerun a tpot but this time around using a restricted configuration of \"simple\" models and see if we ever manage to increase our tpr of the roc curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f48cb32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting our magical tpot\n",
    "tpot.export('tpot_MAGIC_blood_donations_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62a79136",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77cabec1fbc44dd9ae32245ee23175d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.7781501831501831\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.7781501831501831\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.7782051282051282\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.7839377289377288\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.7839377289377288\n",
      "\n",
      "Best pipeline: MultinomialNB(MinMaxScaler(input_matrix), alpha=100.0, fit_prior=False)\n",
      "\n",
      "AUC score: 0.7494\n",
      "\n",
      "Best pipeline steps:\n",
      "1. MinMaxScaler()\n",
      "2. MultinomialNB(alpha=100.0, fit_prior=False)\n"
     ]
    }
   ],
   "source": [
    "#Instantiate the TPOTClassifier\n",
    "tpot_light = TPOTClassifier(generations=5,\n",
    "                     population_size= 20,\n",
    "                     verbosity=2,\n",
    "                     scoring= ['roc_auc'],\n",
    "                     random_state=42,\n",
    "                     disable_update_check=True,\n",
    "                     early_stop =5,\n",
    "                    config_dict= 'TPOT light')\n",
    "\n",
    "tpot_light.fit(X_train,y_train)\n",
    "\n",
    "#roc_auc score \n",
    "y_pred_1= tpot.predict_proba(X_test)[:,1]\n",
    "tpot_light_score = roc_auc_score(y_test , y_pred_1)\n",
    "print(f'\\nAUC score: {tpot_light_score:.4f}')\n",
    "\n",
    "\n",
    "# Print best pipeline steps\n",
    "print('\\nBest pipeline steps:', end='\\n')\n",
    "for idx, (name, transform) in enumerate(tpot_light.fitted_pipeline_.steps, start=1):\n",
    "    # Print idx and transform\n",
    "    print(f'{idx}. {transform}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44c7a00",
   "metadata": {},
   "source": [
    "Using a TPOT light version signaled a slightly decreasing model accuracy, from 79.7% to 78.4%, although the auc score is almost the same as the first tpot.\n",
    "\n",
    "Now, let's see if we can increase this rate by customizing a pipepline to solve this classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8deba7b",
   "metadata": {},
   "source": [
    "# Customized pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460679c0",
   "metadata": {},
   "source": [
    "For this customized pipeline, I'll be training a simple logistic regression first , and work my way through other performing ensemble models while comparing the roc_auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "440082c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation auc score: 0.7363\n",
      "logistic regression auc score on training data : 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#instantiating a logreg pipeline:\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = Pipeline([('scaler', RobustScaler()),\n",
    "                   ('logreg', LogisticRegression(solver='liblinear', random_state=42))])\n",
    "#Cross validation\n",
    "cv_results = cross_validate(logreg ,X_train, y_train, scoring='roc_auc', cv=5, verbose=1, n_jobs=1)['test_score'].mean()\n",
    "print('cross validation auc score:', cv_results.round(4))\n",
    "\n",
    "#roc_auc_score\n",
    "logreg.fit(X_train, y_train)\n",
    "roc_auc_log = roc_auc_score(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "print('logistic regression auc score on training data :', roc_auc_log.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e14c525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-e0d97b5f-0340-4431-92de-823b844546ff {color: black;background-color: white;}#sk-e0d97b5f-0340-4431-92de-823b844546ff pre{padding: 0;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-toggleable {background-color: white;}#sk-e0d97b5f-0340-4431-92de-823b844546ff label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-e0d97b5f-0340-4431-92de-823b844546ff label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-e0d97b5f-0340-4431-92de-823b844546ff label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-e0d97b5f-0340-4431-92de-823b844546ff input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-e0d97b5f-0340-4431-92de-823b844546ff input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-e0d97b5f-0340-4431-92de-823b844546ff input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-estimator:hover {background-color: #d4ebff;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-item {z-index: 1;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-parallel-item:only-child::after {width: 0;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-e0d97b5f-0340-4431-92de-823b844546ff div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-e0d97b5f-0340-4431-92de-823b844546ff\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, RobustScaler()),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"429df386-31c9-41c9-afaf-a7ccfac85e2f\" type=\"checkbox\" ><label for=\"429df386-31c9-41c9-afaf-a7ccfac85e2f\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, RobustScaler()),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d27244b7-def0-4ec6-aff5-f9c8d71f8f89\" type=\"checkbox\" ><label for=\"d27244b7-def0-4ec6-aff5-f9c8d71f8f89\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d1205168-8a20-429c-9214-2a514d70f10a\" type=\"checkbox\" ><label for=\"d1205168-8a20-429c-9214-2a514d70f10a\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', RobustScaler()),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(random_state=42, solver='liblinear'))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50444677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation auc score: 0.6778\n",
      "Random Forest auc score on training data : 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "#Instantiating a random forest pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = Pipeline([('scaler', RobustScaler()),\n",
    "                   ('random_forest', RandomForestClassifier(n_estimators=100))])\n",
    "#Cross validation\n",
    "cv_results_rf = cross_validate(rf_clf, X_train, y_train, scoring='roc_auc', cv=5, verbose=1)['test_score'].mean()\n",
    "print('cross validation auc score:', cv_results_rf.round(4))\n",
    "\n",
    "#roc_auc_score\n",
    "rf_clf.fit(X_train, y_train)\n",
    "roc_auc_rf = roc_auc_score(y_test, rf_clf.predict_proba(X_test)[:,1])\n",
    "print('Random Forest auc score on training data :', roc_auc_rf.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b36e9b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation auc score: 0.6912\n",
      "Random Forest auc score on training data : 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#Instantiating a Gradient Boosting Classifier pipeline\n",
    "gb_clf = Pipeline([('scaler', RobustScaler()),\n",
    "                   ('random_forest', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                                                max_depth=1, random_state=0))\n",
    "                  ])\n",
    "#Cross validation\n",
    "cv_results_gb = cross_validate(gb_clf ,X_train, y_train, scoring='roc_auc', cv=5, verbose=1)['test_score'].mean()\n",
    "print('cross validation auc score:', cv_results_gb.round(4))\n",
    "\n",
    "#roc_auc_score\n",
    "gb_clf.fit(X_train, y_train)\n",
    "roc_auc_gb = roc_auc_score(y_test, gb_clf.predict_proba(X_test)[:,1])\n",
    "print('Random Forest auc score on training data :', roc_auc_gb.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "587f0699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation auc score: 0.6912\n",
      "Random Forest auc score on training data : 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#Instantiating a Gradient Boosting Classifier pipeline\n",
    "gb_clf = Pipeline([('scaler', RobustScaler()),\n",
    "                   ('random_forest', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                                                max_depth=1, random_state=0))\n",
    "                  ])\n",
    "#Cross validation\n",
    "cv_results_gb = cross_validate(gb_clf ,X_train, y_train, scoring='roc_auc', cv=5, verbose=1)['test_score'].mean()\n",
    "print('cross validation auc score:', cv_results_gb.round(4))\n",
    "\n",
    "#roc_auc_score\n",
    "gb_clf.fit(X_train, y_train)\n",
    "roc_auc_gb = roc_auc_score(y_test, gb_clf.predict_proba(X_test)[:,1])\n",
    "print('Random Forest auc score on training data :', roc_auc_gb.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b88e38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation auc score: 0.6851\n",
      "Random Forest auc score on training data : 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "#Instantiating a Gradient Boosting Classifier pipeline\n",
    "svc_clf = Pipeline([('scaler', RobustScaler()),\n",
    "                   ('random_forest', SVC(probability=True))\n",
    "                  ])\n",
    "#Cross validation\n",
    "cv_results_svc = cross_validate(svc_clf ,X_train, y_train, scoring='roc_auc', cv=5, verbose=1)['test_score'].mean()\n",
    "print('cross validation auc score:', cv_results_svc.round(4))\n",
    "\n",
    "#roc_auc_score\n",
    "svc_clf.fit(X_train, y_train)\n",
    "roc_auc_svc = roc_auc_score(y_test, svc_clf.predict_proba(X_test)[:,1])\n",
    "print('Random Forest auc score on training data :', roc_auc_svc.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430aaa1b",
   "metadata": {},
   "source": [
    "## Scores overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f7867f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('logreg', 0.7773987437730127),\n",
       " ('tpot', 0.7493502274204028),\n",
       " ('SVC', 0.7335390946502058),\n",
       " ('rf_clf', 0.7032163742690059),\n",
       " ('gb_clf', 0.7022417153996101)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing itemgetter\n",
    "from operator import itemgetter\n",
    "\n",
    "# Sorting models based on their AUC score from highest to lowest\n",
    "sorted(\n",
    "    [('tpot', tpot_score), ('logreg', roc_auc_log),\n",
    "    ('rf_clf', roc_auc_rf),\n",
    "    ('gb_clf', roc_auc_gb),\n",
    "    ('SVC', roc_auc_svc)],\n",
    "    key=itemgetter(1),\n",
    "    reverse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae35671",
   "metadata": {},
   "source": [
    "Notice our best model is a simple Logistic Regression Model with an auc score of 78%, the highest so far. \n",
    "\n",
    "Let's see if we can slightly tune its hyperparameters and hope for the score increase. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc9ec17",
   "metadata": {},
   "source": [
    "## Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40f26ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler', RobustScaler()),\n",
       "  ('logreg', LogisticRegression(random_state=42, solver='liblinear'))],\n",
       " 'verbose': False,\n",
       " 'scaler': RobustScaler(),\n",
       " 'logreg': LogisticRegression(random_state=42, solver='liblinear'),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__quantile_range': (25.0, 75.0),\n",
       " 'scaler__unit_variance': False,\n",
       " 'scaler__with_centering': True,\n",
       " 'scaler__with_scaling': True,\n",
       " 'logreg__C': 1.0,\n",
       " 'logreg__class_weight': None,\n",
       " 'logreg__dual': False,\n",
       " 'logreg__fit_intercept': True,\n",
       " 'logreg__intercept_scaling': 1,\n",
       " 'logreg__l1_ratio': None,\n",
       " 'logreg__max_iter': 100,\n",
       " 'logreg__multi_class': 'auto',\n",
       " 'logreg__n_jobs': None,\n",
       " 'logreg__penalty': 'l2',\n",
       " 'logreg__random_state': 42,\n",
       " 'logreg__solver': 'liblinear',\n",
       " 'logreg__tol': 0.0001,\n",
       " 'logreg__verbose': 0,\n",
       " 'logreg__warm_start': False}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "943908db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7782600732600733\n",
      "{'logreg__C': 0.1, 'logreg__penalty': 'l2', 'logreg__solver': 'lbfgs'}\n",
      "Pipeline(steps=[('scaler', RobustScaler()),\n",
      "                ('logreg', LogisticRegression(C=0.1, random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "grid= {\"logreg__C\":np.logspace(-3,3,7),\n",
    "       \"logreg__penalty\":[\"l1\",\"l2\"],\n",
    "      \"logreg__solver\": [\"lbfgs\",\"liblinear\",\"saga\"]}\n",
    "search = GridSearchCV(logreg, grid, \n",
    "                           cv = 5,\n",
    "                           n_jobs=-1 \n",
    "                          ) \n",
    "\n",
    "search.fit(X_train ,y_train);\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)\n",
    "print(search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fa929bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7733333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipe = search.best_estimator_\n",
    "y_pred_final = final_pipe.predict(X_test)\n",
    "final_pipe.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba0a54",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The demand for blood fluctuates throughout the year. An accurate forecast for the future supply of blood allows for an appropriate action to be taken ahead of time and therefore saving more lives.\n",
    "\n",
    "In this notebook, we attempted automatic model selection using TPOT and AUC score we got was 0.7493. This is better than simply choosing 0 all the time (the target incidence suggests that such a model would have 76% success rate). We then grid searched params and improved the AUC score by 0.4%. In the field of machine learning, even small improvements in accuracy can be important, depending on the purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9604438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
